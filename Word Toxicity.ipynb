{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abf5c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import featureform as ff\n",
    "import requests\n",
    "from featureform import local\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cd366ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResourceWarning: unclosed file <_io.BufferedWriter name='toxicity_en.csv'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "147594"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/surge-ai/toxicity/main/toxicity_en.csv\"\n",
    "r = requests.get(url)\n",
    "open(\"toxicity_en.csv\", 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7c6c2440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk is a piece of shit, greedy capitalis...</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The senile credit card shrill from Delaware ne...</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He does that a lot -- makes everyone look good...</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F*ck Lizzo</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Epstein and trump were best buds!!! Pedophiles...</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text is_toxic\n",
       "0  Elon Musk is a piece of shit, greedy capitalis...    Toxic\n",
       "1  The senile credit card shrill from Delaware ne...    Toxic\n",
       "2  He does that a lot -- makes everyone look good...    Toxic\n",
       "3                                         F*ck Lizzo    Toxic\n",
       "4  Epstein and trump were best buds!!! Pedophiles...    Toxic"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = local.register_file(\n",
    "    name=\"toxicity_en\",\n",
    "    description=\"A dataset of toxic sentences\",\n",
    "    path=\"toxicity_en.csv\"\n",
    ")\n",
    "df = transactions.pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c39ab2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = ['man', 'woman', 'he', 'she', 'white', 'black', 'asian', 'hispanic', 'rich', 'poor', 'christian', 'muslim', 'jewish',\n",
    "            'transgender', 'non-binary', 'genderqueer', 'genderfluid', 'caucasian', 'indian', 'native american', 'middle eastern', 'latino/latina', 'indigenous', 'middle class', 'working class', 'upper class', 'homeless', 'unemployed', 'buddhist', 'hindu', 'atheist', 'sikh', 'agnostic', 'disabled', 'deaf', 'blind', 'autistic', 'wheelchair-bound', 'child', 'teenager', 'elderly', 'millennial', 'generation z']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a92e629b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'corporate',\n",
       " 'general',\n",
       " 'hauled',\n",
       " 'birb',\n",
       " 'bathroom',\n",
       " 'apologize',\n",
       " 'impressive',\n",
       " 'malfunction',\n",
       " 'mexican',\n",
       " 'title',\n",
       " 'cured',\n",
       " 'gritz',\n",
       " 'he‚Äôs',\n",
       " 'seek',\n",
       " 'todd',\n",
       " 'of',\n",
       " 'windows',\n",
       " 'fuck',\n",
       " 'mob',\n",
       " 'big',\n",
       " 'üñïthat',\n",
       " 'preference',\n",
       " 'skies',\n",
       " 'matter',\n",
       " 'touches',\n",
       " 'melty',\n",
       " 'gang-like',\n",
       " 'dummer',\n",
       " 'comment',\n",
       " 'fucked',\n",
       " 'mention',\n",
       " 'open-face',\n",
       " 'buying',\n",
       " 'jan',\n",
       " 'fu#cking',\n",
       " 'beyond',\n",
       " 'pedophilia',\n",
       " 'belt',\n",
       " 'stupid',\n",
       " 'numorous',\n",
       " 'confidence',\n",
       " 'bought',\n",
       " 'out',\n",
       " 'dudes',\n",
       " 'rewash',\n",
       " 'involved',\n",
       " 'bakery',\n",
       " 'ready',\n",
       " 'adorable',\n",
       " 'deceased',\n",
       " 'investigation',\n",
       " 'covering',\n",
       " 'excuse',\n",
       " 'family‚Äôs',\n",
       " 'deserved',\n",
       " 'navy',\n",
       " 'pencildick',\n",
       " 'savior',\n",
       " 'empty',\n",
       " 'alert',\n",
       " 'dropping',\n",
       " '‚Äúboo',\n",
       " 'lumine',\n",
       " 'cancerous',\n",
       " 'make',\n",
       " 'trades',\n",
       " 'find',\n",
       " 'shout',\n",
       " 'hits',\n",
       " 'yawns',\n",
       " 'survived',\n",
       " 'east',\n",
       " 'hard',\n",
       " 'sheets',\n",
       " 'fucken',\n",
       " 'besides',\n",
       " 'drops',\n",
       " 'slogan',\n",
       " 'movies',\n",
       " 'kid',\n",
       " 'almost',\n",
       " 'hold',\n",
       " 'advantage',\n",
       " 'creating',\n",
       " 'shithead....does',\n",
       " 'yet',\n",
       " 'ranch',\n",
       " 'queens',\n",
       " 'shallnotbeinfringed',\n",
       " '2016',\n",
       " 'double',\n",
       " 'fight',\n",
       " 'foreigners',\n",
       " 'desk',\n",
       " 'entire',\n",
       " 'survivability',\n",
       " 'üòéüòéüòéüòéüòéüòéüòé',\n",
       " 'disorder',\n",
       " 'sama',\n",
       " 'we‚Äôve',\n",
       " 'part',\n",
       " 'jill',\n",
       " 'discarded',\n",
       " 'immigrant',\n",
       " 'joke',\n",
       " 'reap',\n",
       " 'pipe',\n",
       " 'you‚Äôll',\n",
       " 'cancelculture',\n",
       " 'barbarism',\n",
       " 'greedy',\n",
       " 'ai',\n",
       " 'deliberate',\n",
       " 'bjerg',\n",
       " 'sick',\n",
       " 'quarter',\n",
       " 'chop',\n",
       " 'wears',\n",
       " 'dice',\n",
       " 'artwork',\n",
       " 'bread',\n",
       " 'spreading',\n",
       " 'planet',\n",
       " 'boys',\n",
       " 'daphne',\n",
       " 'campus',\n",
       " 'theory',\n",
       " 'damaging',\n",
       " 'them',\n",
       " 'until',\n",
       " 'least',\n",
       " 'hoodie',\n",
       " 'hillary',\n",
       " 'mouth',\n",
       " 'yuumi',\n",
       " 'hang',\n",
       " 'number',\n",
       " 'boss',\n",
       " 'rightwingcult',\n",
       " 'mmm',\n",
       " 'immigrants',\n",
       " 'fascists',\n",
       " 'yhorm',\n",
       " 'scumfuks',\n",
       " 'whistle',\n",
       " 'consequences',\n",
       " 'keepthepowderdry',\n",
       " 'dumbest',\n",
       " 'exercise',\n",
       " 'transhumanist',\n",
       " 'incal',\n",
       " 'best',\n",
       " 'spent',\n",
       " 'crud',\n",
       " 'rating',\n",
       " 'obe',\n",
       " 'maniac',\n",
       " 'remaining',\n",
       " 'get',\n",
       " 'personal',\n",
       " 'nursing',\n",
       " 'i‚Äôm',\n",
       " 'inflation',\n",
       " 'defraud',\n",
       " 'onto',\n",
       " 'ironically',\n",
       " 'aclu',\n",
       " 'spiral',\n",
       " 'rewriting',\n",
       " 'gun‚Ä¶‚Ä¶..how',\n",
       " '18',\n",
       " 'killed',\n",
       " 'tape',\n",
       " 'caramelizing',\n",
       " 'supporting',\n",
       " 'dealers',\n",
       " 'zilch',\n",
       " 'indoctrination',\n",
       " 'comfort',\n",
       " 'canned',\n",
       " 'donate',\n",
       " 'communists',\n",
       " 'schooler',\n",
       " 'tessio',\n",
       " 'together',\n",
       " 'hearts',\n",
       " 'own',\n",
       " 'old',\n",
       " 'virus',\n",
       " 'giggle',\n",
       " 'vicky',\n",
       " 'users',\n",
       " 'relent',\n",
       " 'actions',\n",
       " 'vaccine',\n",
       " 'letters',\n",
       " 'structured',\n",
       " 'household',\n",
       " 'shortly',\n",
       " 'evening',\n",
       " 'dumplings',\n",
       " 'flimflamfool',\n",
       " 'link',\n",
       " 'class',\n",
       " 'debut',\n",
       " 'situationally',\n",
       " 'to‚Ä¶',\n",
       " 'bottom',\n",
       " 'cant',\n",
       " 'artificially',\n",
       " 'applicants',\n",
       " 'goinggoinggoing',\n",
       " 'dirty',\n",
       " 'governments',\n",
       " 'undo',\n",
       " 'clan',\n",
       " 'ignored',\n",
       " 'peter',\n",
       " 'medgar',\n",
       " 'puppies',\n",
       " 'ggg?üò≠',\n",
       " 'prophecy',\n",
       " 'basic',\n",
       " 'magats...even',\n",
       " 'feminism',\n",
       " 'reviewing',\n",
       " 'cupcake',\n",
       " 'minions',\n",
       " 'ago',\n",
       " 'snowflake',\n",
       " 'rise',\n",
       " 'german',\n",
       " 'tarrasques',\n",
       " \"children's\",\n",
       " 'perceptive',\n",
       " 'weeded',\n",
       " 'though',\n",
       " 'ts',\n",
       " 'imitation',\n",
       " 'wave/jungle',\n",
       " 'narcissist,sociopath,psycho',\n",
       " 'politicians',\n",
       " 'difference',\n",
       " 'chiming',\n",
       " 'calling',\n",
       " 'meetings',\n",
       " 'doinb',\n",
       " 'company',\n",
       " 'pentakill',\n",
       " 'plotted',\n",
       " 'reps',\n",
       " 'pop',\n",
       " 'hateful',\n",
       " 'subreddit',\n",
       " 'increased',\n",
       " 'cheating',\n",
       " 'demonic',\n",
       " 'melts',\n",
       " 'vaccinated',\n",
       " 'hitch',\n",
       " 'brushed',\n",
       " 'west',\n",
       " 'photographers',\n",
       " 'actors',\n",
       " 'propaganda',\n",
       " 'draconian',\n",
       " 'through',\n",
       " 'believed',\n",
       " 'meta-sided',\n",
       " 'votes',\n",
       " 'critical',\n",
       " 'too',\n",
       " 'living',\n",
       " 'shit‚Ä¶..and',\n",
       " 'buffoon',\n",
       " 'socialism',\n",
       " 'dmg',\n",
       " 'speed',\n",
       " 'decoding',\n",
       " 'lucky',\n",
       " 'itself',\n",
       " 'pantry',\n",
       " 'obamas',\n",
       " 'cinnamon',\n",
       " 'tied',\n",
       " 'uninformed',\n",
       " 'ramones',\n",
       " 'permission',\n",
       " 'states',\n",
       " 'war',\n",
       " 'applying',\n",
       " 'sinema',\n",
       " \"biden's\",\n",
       " 'asset,traitor,malignant',\n",
       " 'military',\n",
       " 'coming',\n",
       " 'feet',\n",
       " 'favorite',\n",
       " 'horrible',\n",
       " 'its',\n",
       " 'singed',\n",
       " 'froot',\n",
       " 'fucktheleft',\n",
       " 'distortion',\n",
       " 'depression',\n",
       " 'years',\n",
       " 'secret',\n",
       " 'vengeance',\n",
       " 'south',\n",
       " 'soap',\n",
       " 'deeds',\n",
       " 'content',\n",
       " 'cows',\n",
       " 'stitching',\n",
       " 'date',\n",
       " 'coin',\n",
       " 'improving',\n",
       " 'scammy',\n",
       " 'section',\n",
       " 'flock',\n",
       " 'hoes',\n",
       " 'destroying',\n",
       " 'many',\n",
       " 'ability',\n",
       " 'walked',\n",
       " 'roughly',\n",
       " 'hung',\n",
       " 'employs',\n",
       " 'hitler‚Äôs',\n",
       " 'thump',\n",
       " 'meth',\n",
       " 'thanksgiving',\n",
       " 'oldest',\n",
       " 'shares',\n",
       " 'doing',\n",
       " 'attack',\n",
       " 'named',\n",
       " 'allowing',\n",
       " 'weeks',\n",
       " 'precious',\n",
       " 'graphic',\n",
       " 'cleave',\n",
       " 'both',\n",
       " 'senators',\n",
       " 'ivanka',\n",
       " 'bankruptcies',\n",
       " 't-idiot',\n",
       " 'under',\n",
       " 'congress',\n",
       " '‚Äúdinners‚Äù',\n",
       " 'bob',\n",
       " 'same',\n",
       " 'miles',\n",
       " 'b*$trd',\n",
       " \"faker's\",\n",
       " 'kart',\n",
       " 'neonazi',\n",
       " 'again',\n",
       " 'food52',\n",
       " 'provide',\n",
       " 'an',\n",
       " 'shelter',\n",
       " 'forest‚Äù',\n",
       " 'mitch',\n",
       " 'bully',\n",
       " 'first-hand',\n",
       " 'interested',\n",
       " 'cinderhulk',\n",
       " 'savages',\n",
       " 'prosecuting',\n",
       " 'pee',\n",
       " 'hollowed',\n",
       " 'suzy',\n",
       " 'mills',\n",
       " 'hunter',\n",
       " 'lcs',\n",
       " 'hundreds',\n",
       " 'don‚Äôt',\n",
       " 'teammate',\n",
       " 'mountains',\n",
       " 'medium',\n",
       " 'elementary',\n",
       " 'buddy',\n",
       " 'knee',\n",
       " 'soros',\n",
       " 'embracing',\n",
       " 'replaced',\n",
       " '100',\n",
       " 'behind',\n",
       " 'played',\n",
       " 'freak',\n",
       " 'perfect',\n",
       " 'styrofoam',\n",
       " 'walking',\n",
       " 'etc',\n",
       " 'wet',\n",
       " 'position',\n",
       " 'weinstein',\n",
       " 'educated',\n",
       " 'deaths',\n",
       " 'door',\n",
       " 'minds',\n",
       " 'demise',\n",
       " 'progressive',\n",
       " 'handsome',\n",
       " 'designs',\n",
       " 'decayed',\n",
       " 'whites',\n",
       " 'shephard',\n",
       " 'horrid',\n",
       " 'instant',\n",
       " 'guessing',\n",
       " 'defiant',\n",
       " 'near',\n",
       " 'ccn',\n",
       " 'cuz',\n",
       " 'meaning',\n",
       " 'sandwich',\n",
       " 'vaccines',\n",
       " 'runs',\n",
       " 'coronavirus',\n",
       " 'head',\n",
       " 'finding',\n",
       " 'noquarter',\n",
       " 'steal',\n",
       " 'controls',\n",
       " 'airlines',\n",
       " 'rival',\n",
       " 'discovered',\n",
       " 'freespeech',\n",
       " 'af‚Äî',\n",
       " 'three',\n",
       " 'with',\n",
       " \"6'7\",\n",
       " 'travel',\n",
       " 'fraud-a-con',\n",
       " 'demonstrate',\n",
       " 'goes',\n",
       " 'god‚Äôs',\n",
       " 'talent',\n",
       " 'rant',\n",
       " 'certrainly',\n",
       " 'insurance',\n",
       " 'kotor',\n",
       " 'car',\n",
       " 'manner',\n",
       " 'meat',\n",
       " 'disappointed',\n",
       " 'basis',\n",
       " 'brian',\n",
       " 'weapon',\n",
       " 'frogs',\n",
       " 'agendas',\n",
       " 'achieve',\n",
       " 'mess',\n",
       " 'sheep...all',\n",
       " 'champion',\n",
       " '‚òπ',\n",
       " 'worse',\n",
       " 'okay',\n",
       " \"today's\",\n",
       " 'feel',\n",
       " 'fuk',\n",
       " 'trips',\n",
       " '‚Äì',\n",
       " 'parent',\n",
       " 'because',\n",
       " '45',\n",
       " 'screener',\n",
       " 'immature',\n",
       " 'communist',\n",
       " 'maple',\n",
       " 'action',\n",
       " 'doesnt',\n",
       " 'other',\n",
       " 'weighs',\n",
       " 'flayed',\n",
       " 'triggers',\n",
       " 'woodworking',\n",
       " 'passiones',\n",
       " 'supposed',\n",
       " 'revealed',\n",
       " 'congrats',\n",
       " 'treat',\n",
       " 'these',\n",
       " 'trumps',\n",
       " 'cities',\n",
       " 'sky',\n",
       " 'allies',\n",
       " 'e',\n",
       " 'hellandback',\n",
       " 'castellano',\n",
       " 'sure',\n",
       " '‚Äúpresident‚Äù',\n",
       " 'don',\n",
       " 'loves',\n",
       " 'turkey',\n",
       " 'her',\n",
       " 'opened',\n",
       " 'irrelevant',\n",
       " 'obviously',\n",
       " 'o',\n",
       " 'widening',\n",
       " 'duggar‚Äôs',\n",
       " 'collection',\n",
       " \"shyv's\",\n",
       " 'unwanted',\n",
       " 'factored',\n",
       " 'anchors',\n",
       " 'blown',\n",
       " 'cavesa',\n",
       " 'placed',\n",
       " '2a',\n",
       " 'sa\\\\fados',\n",
       " 'base',\n",
       " 'agaisnt',\n",
       " 'later',\n",
       " 'karen',\n",
       " 'pink',\n",
       " 'clue',\n",
       " 'scallion',\n",
       " 'wants',\n",
       " 'ancient',\n",
       " 'flesh',\n",
       " 'vision',\n",
       " 'gold',\n",
       " 'lightfoot',\n",
       " \"doesn't\",\n",
       " 'ford',\n",
       " 'mastriano',\n",
       " 'seat',\n",
       " 'constantly',\n",
       " 'republic',\n",
       " 'follow',\n",
       " 'fux',\n",
       " 'choice',\n",
       " 'hotel',\n",
       " 'thats',\n",
       " 'gravy',\n",
       " 'revenue',\n",
       " 'wales',\n",
       " 'sluts',\n",
       " 'douch',\n",
       " 'joe',\n",
       " 'need',\n",
       " \"michael's\",\n",
       " 'florida',\n",
       " 'dicked',\n",
       " 'sprayed',\n",
       " 'suffer',\n",
       " 'authorities',\n",
       " 'packing',\n",
       " 'ours',\n",
       " 'expect',\n",
       " 'appalling',\n",
       " 'fuckcancelculture',\n",
       " 'prefer',\n",
       " 'shotgun',\n",
       " 'die!you',\n",
       " 'corleones',\n",
       " 'sql',\n",
       " 'wild',\n",
       " 'libtards',\n",
       " 'cares',\n",
       " 'concern',\n",
       " 'moronic',\n",
       " 'court-martialed',\n",
       " 'dares',\n",
       " 'democrat',\n",
       " 'meta',\n",
       " 'processing/preservatives',\n",
       " 'clean',\n",
       " 'jay',\n",
       " 'crying',\n",
       " 'sex',\n",
       " '‚Äúincingdeath‚Äù',\n",
       " 'goddess',\n",
       " 'day',\n",
       " 'notorious',\n",
       " 'why',\n",
       " 'knees',\n",
       " 'fellow',\n",
       " 'haunted',\n",
       " 'sad',\n",
       " 'crazy',\n",
       " 'dates',\n",
       " \"aren't\",\n",
       " 'worthy',\n",
       " \"sheep's\",\n",
       " 'sexual',\n",
       " 'nail',\n",
       " 'fuckboy',\n",
       " 'areas',\n",
       " 'champ',\n",
       " 'stores',\n",
       " 'mind',\n",
       " \"let's\",\n",
       " 'chickens',\n",
       " 'n',\n",
       " 'relationships',\n",
       " 'admittedly',\n",
       " 'geezer',\n",
       " 'afghan',\n",
       " 'em',\n",
       " 'outright',\n",
       " 'torturing',\n",
       " 'taste',\n",
       " 'elites',\n",
       " 'depleted',\n",
       " 'claimed',\n",
       " 'exposure',\n",
       " 'murican',\n",
       " 'week(bil',\n",
       " 'swallow',\n",
       " 'ratio',\n",
       " 'gitmo',\n",
       " 'embarrassing',\n",
       " 'antichrist',\n",
       " 'chopped',\n",
       " 'knowledge',\n",
       " 'biden‚Äôs',\n",
       " 'approved',\n",
       " '‚Äî',\n",
       " 'wow',\n",
       " 'dollar',\n",
       " 'ginger',\n",
       " 'heartbreaker',\n",
       " 'eagle',\n",
       " 'renamed',\n",
       " 'brand',\n",
       " 'glasses',\n",
       " 'clinic',\n",
       " 'offers',\n",
       " 'meme',\n",
       " 'ish',\n",
       " 'biden\\\\hitler',\n",
       " 'douche',\n",
       " 'üë∫ü•µüêñüêëüêÄüêòü¶†‚ò†Ô∏èüé≠üêÄü•µüêñüé≠üêòüí©',\n",
       " 'decision',\n",
       " 'you‚Äôve',\n",
       " 'added',\n",
       " 'panik',\n",
       " 'now‚Äù',\n",
       " \"it'll\",\n",
       " 'loop',\n",
       " 'jokes',\n",
       " '3k',\n",
       " 'ppl',\n",
       " 'bribe',\n",
       " 'vibes',\n",
       " 'soul',\n",
       " 'beat',\n",
       " 'learned',\n",
       " 'choosing',\n",
       " '40/50/70/85/100',\n",
       " '95',\n",
       " 'inevitable',\n",
       " 'trade',\n",
       " 'package',\n",
       " 'sam',\n",
       " 'way',\n",
       " 'shelbyville',\n",
       " 'culture',\n",
       " 'recently',\n",
       " 'raise',\n",
       " 'demon',\n",
       " 'repulsive',\n",
       " 'desire',\n",
       " 'g2',\n",
       " 'illness',\n",
       " 'give',\n",
       " 'upvotes',\n",
       " 'troops',\n",
       " 'powers',\n",
       " 'dragons',\n",
       " 'rosa',\n",
       " 'situations',\n",
       " 'msnbc',\n",
       " 'fella',\n",
       " 'unfortunately',\n",
       " 'arcs',\n",
       " 'boiled',\n",
       " 'labor',\n",
       " 'shitholehood',\n",
       " 'majority',\n",
       " 'me',\n",
       " 'man',\n",
       " 'trying',\n",
       " 'television',\n",
       " 'approval',\n",
       " 'heelsup',\n",
       " 'scary',\n",
       " 'beauty',\n",
       " 'america',\n",
       " 'disrespectful',\n",
       " 'facebook',\n",
       " 'raped',\n",
       " '‚Äúhis',\n",
       " 'trumpty',\n",
       " 'tax',\n",
       " 'letfreedomring',\n",
       " 'correctly',\n",
       " 'shaped',\n",
       " 'teflon¬Æ',\n",
       " 'protest',\n",
       " 'gift',\n",
       " 'gymnastics',\n",
       " 'private',\n",
       " 'disgraceful',\n",
       " 'can`t',\n",
       " 'think',\n",
       " 'charge',\n",
       " 'fits',\n",
       " 'applesauce',\n",
       " 'obama‚Äôs',\n",
       " 'mfkn',\n",
       " 'misdemeanors',\n",
       " 'rape',\n",
       " 'dinner',\n",
       " 'lacks',\n",
       " 'covid19',\n",
       " 'happens',\n",
       " 'pics',\n",
       " 'police',\n",
       " 'a-hole',\n",
       " 'af',\n",
       " 'new',\n",
       " 'idiots',\n",
       " 'pandemic',\n",
       " 'reformated',\n",
       " 'union',\n",
       " 'squad',\n",
       " 'underboss',\n",
       " 'but',\n",
       " 'mission',\n",
       " 'camel',\n",
       " 'bearnessities',\n",
       " 'tables',\n",
       " 'whining',\n",
       " 'reliable',\n",
       " 'sold',\n",
       " 'enough',\n",
       " 'region',\n",
       " 'veraza',\n",
       " \"samira's\",\n",
       " 'clip',\n",
       " 'condensed',\n",
       " 'paternal',\n",
       " 'stronger',\n",
       " 'seju',\n",
       " 'v.p',\n",
       " 'week',\n",
       " 'beijingbidencheated',\n",
       " 'brief',\n",
       " 'macaroni',\n",
       " 'students',\n",
       " 'breast',\n",
       " 'rich',\n",
       " 'baron',\n",
       " 'designer',\n",
       " 'discs',\n",
       " 'clips',\n",
       " 'per',\n",
       " 'boooooo',\n",
       " 'soulless',\n",
       " 'realm',\n",
       " '20-year',\n",
       " 'orchestrated',\n",
       " 'company‚Äôs',\n",
       " 'stupidity',\n",
       " '7:30',\n",
       " 'leadership',\n",
       " 'once',\n",
       " 'toothless',\n",
       " 'moving',\n",
       " 'hugs',\n",
       " 'worries',\n",
       " 'speakers',\n",
       " 'draft',\n",
       " 'park',\n",
       " 'eternal',\n",
       " 'reality',\n",
       " 'hit',\n",
       " 'enticing',\n",
       " 'seriously',\n",
       " 'unless',\n",
       " 'firefighters',\n",
       " 'trolls',\n",
       " 'karma',\n",
       " 'curriculum',\n",
       " 'ears',\n",
       " 'logan',\n",
       " 'ext',\n",
       " 'tesla‚Äôs',\n",
       " 'black',\n",
       " 'rot',\n",
       " 'veterinarians',\n",
       " 'vague',\n",
       " 'busy',\n",
       " 'sickness',\n",
       " 'pups',\n",
       " 'snowballs',\n",
       " 'tre45on',\n",
       " 'endorse',\n",
       " 'emotions',\n",
       " 'winning',\n",
       " 'swamp',\n",
       " 'essay',\n",
       " 'mad',\n",
       " 'elsewhere',\n",
       " 'alone',\n",
       " 'exact',\n",
       " 'elf',\n",
       " 'arteries',\n",
       " 'affection',\n",
       " 'airhead',\n",
       " 'hell',\n",
       " 'victory',\n",
       " 'blackmailed',\n",
       " 'ü§£ü§£ü§£',\n",
       " 'castorate',\n",
       " 'fraud',\n",
       " 'tears',\n",
       " '13',\n",
       " 'f**k',\n",
       " 'lizzo',\n",
       " 'strictly',\n",
       " 'leave',\n",
       " 'men/pedophiles',\n",
       " 'stepped',\n",
       " 'dunshire',\n",
       " 'kids‚Äô',\n",
       " 'authenticity',\n",
       " 'saturday',\n",
       " 'tedcruz',\n",
       " 'country',\n",
       " 'opposite',\n",
       " 'cleaning',\n",
       " 'compliment',\n",
       " 'voted',\n",
       " 'nazis',\n",
       " 'cool',\n",
       " 'rapist,sexual',\n",
       " 'emphasized',\n",
       " 'carrying',\n",
       " 'you‚Äù',\n",
       " 'air-fryed',\n",
       " 'destinations',\n",
       " 'twinkling',\n",
       " 'bowl',\n",
       " 'careers',\n",
       " 'poor',\n",
       " '420',\n",
       " 'right',\n",
       " 'cuomo',\n",
       " 'jogs',\n",
       " \"house....it's\",\n",
       " 'üòÜ',\n",
       " 'lets',\n",
       " 'niece',\n",
       " 'birch',\n",
       " 'nailed',\n",
       " 'awareness',\n",
       " 'eye',\n",
       " 'hula',\n",
       " 'pull',\n",
       " 'version',\n",
       " 'ay',\n",
       " 'yum',\n",
       " 'terrorists',\n",
       " 'transfer',\n",
       " 'nyc',\n",
       " 'phd',\n",
       " 'whereas',\n",
       " 'eat‚Ä¶‚Ä¶you',\n",
       " 'honey',\n",
       " 'bullshit',\n",
       " 'abuelita',\n",
       " 'late',\n",
       " 'working',\n",
       " 'falling',\n",
       " 'losing',\n",
       " 'puck',\n",
       " 'earned',\n",
       " 'carried',\n",
       " 'elderly',\n",
       " 'miserable',\n",
       " 'deserve',\n",
       " 'passes',\n",
       " 'seem',\n",
       " 'tee',\n",
       " 'hopefully',\n",
       " 'creators',\n",
       " 'fafo',\n",
       " 'slicker',\n",
       " 'underestimate',\n",
       " '100,000',\n",
       " 'there',\n",
       " 'designed',\n",
       " 'us',\n",
       " 'books',\n",
       " 'announcement',\n",
       " 'demands',\n",
       " 'tactics',\n",
       " 'retail',\n",
       " 'congratulations',\n",
       " 'fauci',\n",
       " 'allways',\n",
       " 'capable',\n",
       " 'amarica',\n",
       " 'lame',\n",
       " 'sign',\n",
       " 'politicalmemes',\n",
       " 'passive',\n",
       " 'americanpride',\n",
       " 'wallet',\n",
       " 'fascist',\n",
       " 'backyards',\n",
       " 'high',\n",
       " 'comparing',\n",
       " 'crowder',\n",
       " 'sett',\n",
       " 'our',\n",
       " 'shared',\n",
       " 'degenerates',\n",
       " 'brighter',\n",
       " 'holy',\n",
       " 'dumbasses',\n",
       " 'moebius',\n",
       " 'core',\n",
       " 'fingers',\n",
       " 'larger',\n",
       " 'dickhead',\n",
       " 'series',\n",
       " 'scheming',\n",
       " 'roast',\n",
       " 'raged',\n",
       " 'loppy',\n",
       " 'heartless',\n",
       " 'cheap',\n",
       " 'longer',\n",
       " 'john',\n",
       " 'granted',\n",
       " 'kids',\n",
       " 'head-on',\n",
       " 'fool‚Äù',\n",
       " 'democrats',\n",
       " 'photo',\n",
       " 'incessant',\n",
       " 'grief',\n",
       " 'slapping',\n",
       " 'joy..the',\n",
       " 'lied',\n",
       " 'sh',\n",
       " 'haha',\n",
       " 'religious',\n",
       " \"we've\",\n",
       " \"what's\",\n",
       " 'comes',\n",
       " 'hydrated',\n",
       " 'originally',\n",
       " 'quirky',\n",
       " 'opening',\n",
       " 'defend',\n",
       " 'tweets',\n",
       " 'gone',\n",
       " 'character',\n",
       " 'being',\n",
       " 'jinx',\n",
       " 'garbage',\n",
       " 'maggot',\n",
       " 'horror',\n",
       " 'lil',\n",
       " 'control',\n",
       " 'traitortrump',\n",
       " 'thrives',\n",
       " 'doodle',\n",
       " 'laced',\n",
       " 'their.hands',\n",
       " 'left',\n",
       " 'training',\n",
       " 'top',\n",
       " 'pedos',\n",
       " 'idiotic',\n",
       " 'important',\n",
       " 'furies',\n",
       " 'teddy',\n",
       " 'expert',\n",
       " 'island',\n",
       " 'thermostat',\n",
       " 'bowls',\n",
       " 'film',\n",
       " 'wouldn‚Äôt',\n",
       " 'address',\n",
       " 'inferior',\n",
       " 'pukes',\n",
       " 'smartest',\n",
       " 'rico',\n",
       " 'wrinkled',\n",
       " ...}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_words(dataset):\n",
    "    # Concatenate all text data into a single string\n",
    "    text = ' '.join(dataset['text'])\n",
    "\n",
    "    # Tokenize the string into individual words\n",
    "    words = text.split()\n",
    "\n",
    "    # Convert words to lowercase and remove punctuation\n",
    "    words = [word.lower().strip(string.punctuation) for word in words]\n",
    "\n",
    "    # Create a set of unique words\n",
    "    unique_words = set(words)\n",
    "\n",
    "    return unique_words\n",
    "\n",
    "# Assuming 'df' is your dataset DataFrame\n",
    "unique_words = get_unique_words(df)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab1ead12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize word frequency counters for 'Toxic' and 'Not Toxic' rows\n",
    "toxic_word_frequencies = Counter()\n",
    "not_toxic_word_frequencies = Counter()\n",
    "\n",
    "# Iterate over the rows\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']  # Assuming 'text' is the column containing the comments\n",
    "\n",
    "    # Tokenize the text\n",
    "    words = text.lower().split()  # You might need a more sophisticated tokenizer\n",
    "\n",
    "    # Count word frequencies based on the classification\n",
    "    if row['is_toxic'] == 'Toxic':\n",
    "        toxic_word_frequencies.update(words)\n",
    "    elif row['is_toxic'] == 'Not Toxic':\n",
    "        not_toxic_word_frequencies.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0d48f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_frequencies(df):\n",
    "    results_df = pd.DataFrame({\n",
    "        'Word': unique_words,\n",
    "        'Toxic Frequency': [toxic_word_frequencies[word] for word in unique_words],\n",
    "        'Not Toxic Frequency': [not_toxic_word_frequencies[word] for word in unique_words]\n",
    "    })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "945b7e9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' type is unordered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4v/ky8twf6j5jq5b6fx7w4k_jyr0000gn/T/ipykernel_2752/1163824996.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate_word_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/4v/ky8twf6j5jq5b6fx7w4k_jyr0000gn/T/ipykernel_2752/3050571913.py\u001b[0m in \u001b[0;36mcalculate_word_frequencies\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_word_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     results_df = pd.DataFrame({\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;34m'Word'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munique_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m'Toxic Frequency'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoxic_word_frequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'Not Toxic Frequency'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnot_toxic_word_frequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     return arrays_to_mgr(\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    587\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             val = sanitize_array(\n\u001b[0m\u001b[1;32m    590\u001b[0m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;31m# Raise only for unordered sets, e.g., not for dict_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(data).__name__}' type is unordered\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;31m# materialize e.g. generators, convert e.g. tuples, abc.ValueView\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'set' type is unordered"
     ]
    }
   ],
   "source": [
    "calculate_word_frequencies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d543c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
